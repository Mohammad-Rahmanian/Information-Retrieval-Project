{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d28169",
   "metadata": {},
   "source": [
    "# Information Retrival Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4d5d6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1- Positional Index Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45c2cc",
   "metadata": {},
   "source": [
    "1.1 Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b9af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hazm\n",
    "import math\n",
    "with open('IR_data_news_12k.json', 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "content_dataset, url_dataset, title_dataset = [], [], []\n",
    "for _, data in json_data.items():\n",
    "    content_dataset.append(data[\"content\"])\n",
    "    url_dataset.append(data[\"url\"])\n",
    "    title_dataset.append(data[\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b523d7",
   "metadata": {},
   "source": [
    "1.2 Preprocess Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a182bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = hazm.stopwords_list()\n",
    "punctuations = [')', '(', '>', '<', \"؛\", \"،\", '{', '}', \"؟\", ':', \"–\", '»', '\"', '«', '[', ']', '\"', '+', '=', '?', '/',\n",
    "                '//', '\\\\', '|', '!', '%', '&', '*', '$', '#', '؟', '*', '.', '_', '']\n",
    "normalizer = hazm.Normalizer()\n",
    "lemmatizer = hazm.Lemmatizer()\n",
    "tokens = []\n",
    "for i in range(len(content_dataset)):\n",
    "    content_dataset[i] = normalizer.normalize(content_dataset[i])\n",
    "    first_word_tokens_list = hazm.word_tokenize(content_dataset[i])\n",
    "    second_word_tokens_list = []\n",
    "    final_word_tokens_list = []\n",
    "    for word_token in first_word_tokens_list:\n",
    "        if word_token not in stop_words and word_token not in punctuations:\n",
    "            second_word_tokens_list.append(word_token)\n",
    "    for j in range(len(second_word_tokens_list)):\n",
    "        stem_lammatize = lemmatizer.lemmatize(second_word_tokens_list[j])\n",
    "        if lemmatizer not in final_word_tokens_list:\n",
    "            if stem_lammatize != '':\n",
    "                final_word_tokens_list.append(stem_lammatize)\n",
    "    for word_token in final_word_tokens_list:\n",
    "        tokens.append((word_token, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2c4a7",
   "metadata": {},
   "source": [
    "1.3 Sort Tokens and Create Positional Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e0dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort Tokens\n",
    "tokens.sort(key=lambda a: a[0])\n",
    "positional_index = {}\n",
    "\n",
    "# create postings list\n",
    "last_token = None\n",
    "last_doc_id = None\n",
    "for i in range(len(tokens)):\n",
    "    positional_postings = {}\n",
    "    positions = []\n",
    "    token_i, doc_id_i = tokens[i]\n",
    "    if token_i != last_token:\n",
    "        positional_postings[doc_id_i] = (positions, 0)\n",
    "        positional_index[token_i] = (1, positional_postings)\n",
    "    else:\n",
    "        if doc_id_i != last_doc_id:\n",
    "            positional_postings = positional_index[token_i][1]\n",
    "            positional_postings[doc_id_i] = (positions, 0)\n",
    "            positional_index[token_i] = (positional_index[token_i][0] + 1, positional_postings)\n",
    "    last_token = token_i\n",
    "    last_doc_id = doc_id_i\n",
    "# create positional index\n",
    "for i in range(len(content_dataset)):\n",
    "    word_tokens_list = hazm.word_tokenize(content_dataset[i])\n",
    "    positional_postings = {}\n",
    "    for position, word_token in enumerate(word_tokens_list):\n",
    "        stem_lammatize = lemmatizer.lemmatize(word_token)\n",
    "        token = None\n",
    "        if stem_lammatize in positional_index.keys():\n",
    "            positional_postings = positional_index[stem_lammatize][1]\n",
    "            if i in positional_postings.keys():\n",
    "                positions = positional_postings[i][0]\n",
    "                positions.append(position)\n",
    "                positional_postings[i] = (positions, positional_postings[i][1] + 1)\n",
    "                positional_index[stem_lammatize] = (positional_index[stem_lammatize][0], positional_postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88208dc3",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5516181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequencies in all documents:301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docId=1 positions=[7] ,docId=3 positions=[215] ,docId=16 positions=[189] ,docId=52 positions=[224] ,docId=62 positions=[437] ,docId=65 positions=[184] ,docId=77 positions=[51] ,docId=116 positions=[357] ,docId=128 positions=[260] ,docId=140 positions=[654, 1351] ,docId=232 positions=[126] ,docId=274 positions=[139] ,docId=277 positions=[537, 621] ,docId=278 positions=[205] ,docId=291 positions=[84] ,docId=315 positions=[6] ,docId=350 positions=[65, 70] ,docId=376 positions=[376] ,docId=378 positions=[6, 196, 396] ,docId=435 positions=[624] ,docId=449 positions=[589, 656] ,docId=468 positions=[28, 52] ,docId=472 positions=[140] ,docId=501 positions=[106, 288] ,docId=529 positions=[34] ,docId=531 positions=[30] ,docId=532 positions=[8] ,docId=535 positions=[9, 117, 120, 414, 773] ,docId=538 positions=[33] ,docId=544 positions=[600] ,docId=562 positions=[527] ,docId=569 positions=[8, 259] ,docId=576 positions=[16, 25] ,docId=577 positions=[8, 240, 477] ,docId=707 positions=[20, 27, 223, 448] ,docId=739 positions=[450] ,docId=756 positions=[17] ,docId=790 positions=[80] ,docId=872 positions=[132, 360, 607] ,docId=907 positions=[15] ,docId=935 positions=[131] ,docId=940 positions=[108, 112] ,docId=976 positions=[16, 36, 87, 180, 301, 348, 383] ,docId=1065 positions=[70, 73] ,docId=1146 positions=[9] ,docId=1170 positions=[69] ,docId=1207 positions=[160] ,docId=1237 positions=[157] ,docId=1252 positions=[117, 754] ,docId=1263 positions=[934] ,docId=1336 positions=[203, 330] ,docId=1375 positions=[100] ,docId=1388 positions=[65] ,docId=1393 positions=[314] ,docId=1394 positions=[64, 125] ,docId=1399 positions=[46] ,docId=1401 positions=[54, 141] ,docId=1415 positions=[144] ,docId=1444 positions=[24] ,docId=1487 positions=[42] ,docId=1505 positions=[38] ,docId=1515 positions=[32] ,docId=1527 positions=[159] ,docId=1578 positions=[36, 109, 291, 401] ,docId=1633 positions=[1576, 1612] ,docId=1646 positions=[27] ,docId=1647 positions=[196] ,docId=1672 positions=[30] ,docId=1719 positions=[15] ,docId=1801 positions=[551] ,docId=1816 positions=[762, 887, 966] ,docId=1819 positions=[329, 511, 518] ,docId=2076 positions=[878] ,docId=2079 positions=[50, 149, 437] ,docId=2110 positions=[479] ,docId=2112 positions=[278] ,docId=2121 positions=[35] ,docId=2127 positions=[8] ,docId=2129 positions=[9] ,docId=2133 positions=[9] ,docId=2189 positions=[286, 304, 429] ,docId=2200 positions=[153, 271] ,docId=2216 positions=[43] ,docId=2313 positions=[7, 172] ,docId=2327 positions=[221] ,docId=2341 positions=[142] ,docId=2355 positions=[9, 199, 415] ,docId=2358 positions=[219] ,docId=2408 positions=[555] ,docId=2485 positions=[1428] ,docId=2540 positions=[142] ,docId=2553 positions=[209] ,docId=2698 positions=[6, 248, 489] ,docId=2727 positions=[163] ,docId=2758 positions=[1416] ,docId=2807 positions=[77] ,docId=2829 positions=[13, 77] ,docId=2857 positions=[119] ,docId=2883 positions=[7] ,docId=2892 positions=[242] ,docId=2895 positions=[5] ,docId=2912 positions=[30, 235] ,docId=2939 positions=[65] ,docId=2998 positions=[7, 110] ,docId=3012 positions=[232, 663] ,docId=3021 positions=[9] ,docId=3037 positions=[353] ,docId=3040 positions=[14, 65] ,docId=3106 positions=[8, 407, 692, 978, 1255] ,docId=3110 positions=[46] ,docId=3172 positions=[31] ,docId=3195 positions=[329] ,docId=3208 positions=[93] ,docId=3218 positions=[41, 51, 118, 173, 206] ,docId=3221 positions=[8, 178, 344, 571] ,docId=3222 positions=[201, 303] ,docId=3228 positions=[32] ,docId=3247 positions=[68, 71] ,docId=3277 positions=[6] ,docId=3305 positions=[375] ,docId=3306 positions=[34] ,docId=3312 positions=[7] ,docId=3347 positions=[174] ,docId=3405 positions=[44] ,docId=3416 positions=[84, 107] ,docId=3457 positions=[1207] ,docId=3467 positions=[6, 39, 131, 212] ,docId=3469 positions=[166] ,docId=3473 positions=[6, 183] ,docId=3482 positions=[43] ,docId=3509 positions=[39] ,docId=3516 positions=[119] ,docId=3526 positions=[149, 197] ,docId=3528 positions=[6, 97] ,docId=3529 positions=[33] ,docId=3556 positions=[390, 476] ,docId=3594 positions=[59] ,docId=3603 positions=[25, 38] ,docId=3620 positions=[720, 739] ,docId=3630 positions=[88] ,docId=3646 positions=[52] ,docId=3672 positions=[173] ,docId=3691 positions=[81] ,docId=3694 positions=[560] ,docId=3732 positions=[227, 262] ,docId=3748 positions=[9] ,docId=3762 positions=[8, 126, 349, 518, 619, 816] ,docId=3767 positions=[44, 66, 268] ,docId=3776 positions=[72] ,docId=3782 positions=[148] ,docId=3875 positions=[553] ,docId=3882 positions=[60] ,docId=3887 positions=[159] ,docId=3916 positions=[107] ,docId=4002 positions=[321] ,docId=4042 positions=[5] ,docId=4071 positions=[830, 1018] ,docId=4094 positions=[489] ,docId=4104 positions=[8] ,docId=4146 positions=[352, 399] ,docId=4167 positions=[8, 133, 189, 315] ,docId=4173 positions=[70] ,docId=4176 positions=[205] ,docId=4177 positions=[9] ,docId=4186 positions=[9] ,docId=4187 positions=[9] ,docId=4214 positions=[56] ,docId=4236 positions=[172] ,docId=4252 positions=[578] ,docId=4311 positions=[115] ,docId=4317 positions=[30, 68] ,docId=4322 positions=[88] ,docId=4324 positions=[254, 305, 358] ,docId=4345 positions=[72, 322, 482, 679] ,docId=4376 positions=[155, 392] ,docId=4381 positions=[89] ,docId=4385 positions=[114, 323] ,docId=4387 positions=[10, 204, 432, 763] ,docId=4406 positions=[63] ,docId=4451 positions=[821] ,docId=4469 positions=[115, 230, 322] ,docId=4509 positions=[102] ,docId=4576 positions=[43] ,docId=4605 positions=[159] ,docId=4607 positions=[81] ,docId=4625 positions=[0] ,docId=4739 positions=[170] ,docId=4756 positions=[6, 117] ,docId=4817 positions=[29, 68] ,docId=4828 positions=[219, 266] ,docId=4870 positions=[29] ,docId=4873 positions=[553] ,docId=4906 positions=[6, 305] ,docId=4976 positions=[15, 95] ,docId=4992 positions=[6] ,docId=5009 positions=[125] ,docId=5013 positions=[249] ,docId=5022 positions=[161] ,docId=5029 positions=[221] ,docId=5054 positions=[508] ,docId=5097 positions=[8, 37, 277, 287] ,docId=5108 positions=[287, 345] ,docId=5142 positions=[6, 204] ,docId=5180 positions=[75] ,docId=5213 positions=[27] ,docId=5222 positions=[146, 200, 495] ,docId=5233 positions=[331] ,docId=5240 positions=[6, 38] ,docId=5254 positions=[426] ,docId=5262 positions=[404, 409] ,docId=5268 positions=[1969] ,docId=5338 positions=[536] ,docId=5361 positions=[249] ,docId=5421 positions=[8, 155] ,docId=5445 positions=[8, 271, 805, 1165, 1561, 1688, 2123, 2380] ,docId=5587 positions=[68] ,docId=5594 positions=[61] ,docId=5621 positions=[264] ,docId=5632 positions=[254] ,docId=5661 positions=[37, 52] ,docId=5690 positions=[6] ,docId=5718 positions=[20, 59] ,docId=5726 positions=[25, 58] ,docId=5729 positions=[8, 68, 333, 923] ,docId=5734 positions=[19, 59, 77, 174, 279] ,docId=5746 positions=[16] ,docId=5767 positions=[265] ,docId=5771 positions=[671] ,docId=5833 positions=[240, 613] ,docId=5857 positions=[71] ,docId=5864 positions=[139] ,docId=5885 positions=[187] ,docId=5896 positions=[1102, 1166] ,docId=5935 positions=[318] ,docId=5972 positions=[168] ,docId=5989 positions=[195, 247] ,docId=6037 positions=[6, 99] ,docId=6076 positions=[77] ,docId=6078 positions=[524] ,docId=6083 positions=[118] ,docId=6104 positions=[29] ,docId=6128 positions=[353] ,docId=6167 positions=[8, 108] ,docId=6170 positions=[207] ,docId=6178 positions=[217, 1188] ,docId=6217 positions=[341, 347] ,docId=6230 positions=[151] ,docId=6248 positions=[53] ,docId=6306 positions=[149] ,docId=6312 positions=[186] ,docId=6436 positions=[720, 784, 809, 826, 898, 931, 956, 975, 2727, 2772, 2794, 2819, 2984, 3409, 3517, 4551, 6524, 6551] ,docId=6508 positions=[170] ,docId=6551 positions=[210, 330] ,docId=6557 positions=[94, 207, 603] ,docId=6558 positions=[53, 68] ,docId=6569 positions=[134] ,docId=6570 positions=[52] ,docId=6587 positions=[38] ,docId=6701 positions=[262, 269] ,docId=6759 positions=[288, 300, 658, 667, 772, 956] ,docId=6817 positions=[304] ,docId=6843 positions=[10, 146, 281, 383] ,docId=6982 positions=[138] ,docId=6999 positions=[114] ,docId=7032 positions=[67, 138, 466] ,docId=7059 positions=[114] ,docId=7092 positions=[36] ,docId=7217 positions=[424] ,docId=7258 positions=[1306] ,docId=7480 positions=[1, 213, 363, 518, 703, 936] ,docId=7579 positions=[1379] ,docId=7689 positions=[238] ,docId=7741 positions=[143] ,docId=7765 positions=[526] ,docId=7796 positions=[310] ,docId=7819 positions=[308] ,docId=7830 positions=[285] ,docId=8265 positions=[615] ,docId=8539 positions=[1, 265, 403, 576] ,docId=8780 positions=[1147] ,docId=8828 positions=[55] ,docId=8832 positions=[9, 239, 382] ,docId=8856 positions=[92] ,docId=9239 positions=[595] ,docId=9845 positions=[1467] ,docId=9916 positions=[1443] ,docId=9925 positions=[11] ,docId=9933 positions=[285] ,docId=10082 positions=[32] ,docId=10139 positions=[2977] ,docId=10153 positions=[9, 137, 575, 932] ,docId=10279 positions=[131, 429] ,docId=10649 positions=[51, 577] ,docId=10711 positions=[839] ,docId=10825 positions=[39] ,docId=10905 positions=[282] ,docId=10924 positions=[32, 94] ,docId=11053 positions=[74] ,docId=11434 positions=[223] ,docId=11848 positions=[142] ,docId=12182 positions=[12] ,"
     ]
    }
   ],
   "source": [
    "term = 'سجاد'\n",
    "print(\"Number of frequencies in all documents:\" + str(positional_index[term][0]))\n",
    "# print(\"List of docId:\" + str(positional_index[term][1].keys()))\n",
    "for docID, positional_postings in positional_index[term][1].items():\n",
    "    positions = positional_postings[0]\n",
    "    print(\"docId=\" + str(docID) + \" positions=\" + str(positions) + \" ,\", end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a994312",
   "metadata": {},
   "source": [
    "1.4 Answering Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f769ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marhale 3\n",
    "# query = 'باشگاه‌های فوتسال !آسیا'\n",
    "query = '\"سهمیه المپیک\"'\n",
    "# split query\n",
    "split_query = query.split(\" \")\n",
    "see_str = False\n",
    "phrase_str = ''\n",
    "phrase_list = []\n",
    "not_list = []\n",
    "and_list = []\n",
    "for split_word in split_query:\n",
    "    if '\"' in split_word:\n",
    "        if not see_str:\n",
    "            phrase_str += split_word.split('\"')[1]\n",
    "            see_str = True\n",
    "        else:\n",
    "            phrase_str += \" \" + split_word.split('\"')[0]\n",
    "\n",
    "            see_str = False\n",
    "            phrase_list.append(phrase_str)\n",
    "            phrase_str = ''\n",
    "    elif see_str:\n",
    "        phrase_str += \" \" + split_word\n",
    "\n",
    "    elif '!' in split_word:\n",
    "        not_list.append(split_word.split('!')[1])\n",
    "\n",
    "    else:\n",
    "        and_list.append(split_word)\n",
    "and_list_tokens = []\n",
    "for i in range(len(and_list)):\n",
    "    word = normalizer.normalize(and_list[i])\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "    and_list_tokens.append(word)\n",
    "not_list_tokens = []\n",
    "for i in range(len(not_list)):\n",
    "    word = normalizer.normalize(not_list[i])\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "    not_list_tokens.append(word)\n",
    "phrase_list_tokens = []\n",
    "for i in range(len(phrase_list)):\n",
    "    phrase = normalizer.normalize(phrase_list[i])\n",
    "    phrase_list_tokens.append(phrase)\n",
    "\n",
    "ranked_result_docs = {}\n",
    "\n",
    "# intersect\n",
    "for i in range(len(and_list_tokens)):\n",
    "    if and_list_tokens[i] in positional_index.keys():\n",
    "        result_docs = positional_index[and_list_tokens[i]][1].keys()\n",
    "        for doc in result_docs:\n",
    "            if doc not in ranked_result_docs.keys():\n",
    "                ranked_result_docs[doc] = 1\n",
    "            else:\n",
    "                ranked_result_docs[doc] = ranked_result_docs[doc] + 1\n",
    "# not\n",
    "for i in range(len(not_list_tokens)):\n",
    "    if not_list_tokens[i] in positional_index.keys():\n",
    "        result_docs = positional_index[not_list_tokens[i]][1].keys()\n",
    "        for doc in result_docs:\n",
    "            if doc in ranked_result_docs.keys():\n",
    "                ranked_result_docs.pop(doc)\n",
    "\n",
    "# phrase\n",
    "doc_id_with_last_phrase_position = {}\n",
    "for i in range(len(phrase_list_tokens)):\n",
    "    result_docs = []\n",
    "    phrase_words = phrase_list_tokens[i].split(\" \")\n",
    "    for word in phrase_words:\n",
    "        word_lemmatize = lemmatizer.lemmatize(word)\n",
    "        if word_lemmatize in positional_index.keys():\n",
    "            result_docs.append(positional_index[word_lemmatize][1])\n",
    "\n",
    "    for first_doc_id in result_docs[0].keys():\n",
    "        for second_doc_id in result_docs[1].keys():\n",
    "            if first_doc_id == second_doc_id:\n",
    "                positions_list = []\n",
    "                first_positions_list = result_docs[0][first_doc_id][0]\n",
    "                second_positions_list = result_docs[1][second_doc_id][0]\n",
    "                for position1 in first_positions_list:\n",
    "                    for position2 in second_positions_list:\n",
    "                        if position1 + 1 == position2:\n",
    "                            positions_list.append(position2)\n",
    "                if len(positions_list) != 0:\n",
    "                    doc_id_with_last_phrase_position[first_doc_id] = positions_list\n",
    "    if len(doc_id_with_last_phrase_position) != 0:\n",
    "        for j in range(2, len(result_docs)):\n",
    "            new_doc_id_with_last_position = {}\n",
    "            for doc_id in result_docs[j].keys():\n",
    "                new_positions_list = []\n",
    "                if doc_id in doc_id_with_last_phrase_position.keys():\n",
    "                    positions_list = result_docs[j][doc_id][0]\n",
    "                    for position1 in doc_id_with_last_phrase_position[doc_id]:\n",
    "                        for position2 in positions_list:\n",
    "\n",
    "                            if position1 + 1 == position2:\n",
    "                                new_positions_list.append(position2)\n",
    "                if len(new_positions_list) != 0:\n",
    "                    new_doc_id_with_last_position[doc_id] = new_positions_list\n",
    "            doc_id_with_last_phrase_position = new_doc_id_with_last_position\n",
    "\n",
    "    for doc_id in doc_id_with_last_phrase_position.keys():\n",
    "        if doc_id not in ranked_result_docs.keys():\n",
    "            ranked_result_docs[doc_id] = 1\n",
    "        else:\n",
    "            ranked_result_docs[doc_id] = ranked_result_docs[doc_id] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7f465",
   "metadata": {},
   "source": [
    "1.5 Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4675844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 86:\n",
      "نشست خبری جشنواره یکصد برای انتخاب برترین‌های قرن ورزش ایران برگزار شد\n",
      "\n",
      "        Sentence 1:\n",
      "رشته‌هایی که در آسیا مدال گرفتند یا سهمیه المپیک  گرفتند سه نامزد معرفی می‌کنند.\n",
      "\n",
      "Document 164:\n",
      "رستمیان: رنکینگ ما در کسب سهمیه المپیک مهم است/حضور در جام جهانی قطعی نیست\n",
      "\n",
      "        Sentence 1:\n",
      "وی گفت : امتیاز این مسابقات خیلی مهم است چون از روی رنکینگ سهمیه المپیک  توزیع می‌شود ، باید بتوانیم جایگاه خود را در رنکینگ حفظ کنیم.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "از همین حالا امتیاز مسابقات و رنکینگ ما در توزیع سهمیه المپیک  پاریس تاثیرگذار است.\n",
      "\n",
      "Document 228:\n",
      "گلخندان: مدال فروغی در المپیک مشوق خوبی برای همه بود/ نمی‌توان برای بازی‌های آسیایی قول داد\n",
      "\n",
      "        Sentence 1:\n",
      "وی در خصوص کسب سهمیه المپیک  از طریق رنکینگ جهانی ، گفت : از سال گذشته فدراسیون جهانی برای سهمیه المپیک رنکینگ را مدنظر قرار داد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "کسانی که رنکینگ جهانی داشته_باشند با قوانین خاصی می‌توانند سهمیه المپیک  بگیرند اما همیشه شرکت در هر مسابقه جهانی در رنکینگ تاثیر داشته_است.\n",
      "\n",
      "Document 458:\n",
      "میراسماعیلی: دلسوزی دبیر نفع شخصی نیست و همه عدالت می خواهیم/دروغ می گویند ورزش، سیاسی نیست\n",
      "\n",
      "        Sentence 1:\n",
      "باید برنامه ریزی دقیق‌تر و تلاش بیشتری کنیم زیرا بازی‌های آسیایی و کسب سهمیه المپیک  را پیش رو داریم.\n",
      "\n",
      "Document 562:\n",
      "داورزنی: از وزارت ورزش پول نمی‌خواهیم/ حضور در جمع برترین‌ها زمان‌بر است\n",
      "\n",
      "        Sentence 1:\n",
      "نتوانستیم در المپیک ۲۰۰۸ و ۲۰۱۲ حضور داشته_باشیم ولی در گام سوم توانستم بعد از ۵۳ سال سهمیه المپیک  ۲۰۱۶ کسب کنیم.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranked_result_docs = dict(sorted(ranked_result_docs.items(), key=lambda x: x[1], reverse=True))\n",
    "for i, (doc_id, number) in enumerate(ranked_result_docs.items()):\n",
    "    positions = []\n",
    "    sentences = []\n",
    "    for word in and_list_tokens:\n",
    "        if word in positional_index.keys():\n",
    "            if doc_id in positional_index[word][1].keys():\n",
    "                for position in positional_index[word][1][doc_id][0]:\n",
    "                    positions.append(position)\n",
    "    if doc_id in doc_id_with_last_phrase_position.keys():\n",
    "        for position in doc_id_with_last_phrase_position[doc_id]:\n",
    "            positions.append(position)\n",
    "\n",
    "    if i < 5:\n",
    "        print(\"Document \" + str(doc_id) + \":\")\n",
    "\n",
    "        print(title_dataset[doc_id])\n",
    "\n",
    "        doc_words = hazm.word_tokenize(content_dataset[doc_id])\n",
    "        for count, word in enumerate(doc_words):\n",
    "            if count in positions:\n",
    "                sentence = ''\n",
    "                for k in range(count, -1, -1):\n",
    "                    if doc_words[k] != '.':\n",
    "                        if k in positions:\n",
    "                            positions.remove(k)\n",
    "                        sentence = doc_words[k] + ' ' + sentence\n",
    "                    else:\n",
    "                        break\n",
    "                for j in range(count + 1, len(doc_words)):\n",
    "                    if doc_words[j] != '.':\n",
    "                        if j in positions:\n",
    "                            positions.remove(j)\n",
    "                        sentence = sentence + ' ' + doc_words[j]\n",
    "                    else:\n",
    "                        sentence += '.'\n",
    "                        break\n",
    "\n",
    "                sentences.append(sentence)\n",
    "        for num, sentence in enumerate(sentences):\n",
    "            print(\"\\n        Sentence \" + str(num + 1) + \":\")\n",
    "            print(sentence + '\\n')\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e9bb4",
   "metadata": {},
   "source": [
    "# 2- Ranked Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d46271",
   "metadata": {},
   "source": [
    "2.1 Calculate Cosine Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb42f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_tf_and_length(query):\n",
    "    query_tf = {}\n",
    "    for term in query.split(\" \"):\n",
    "        word = normalizer.normalize(term)\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        if word in query_tf.keys():\n",
    "            query_tf[word] += 1\n",
    "        else:\n",
    "            query_tf[word] = 1\n",
    "    query_length = 0\n",
    "    for term in query_tf.keys():\n",
    "        query_tf[term] = 1 + math.log2(query_tf[term])\n",
    "    for term in query_tf.keys():\n",
    "        query_length += query_tf[term] ** 2\n",
    "    return query_tf, math.sqrt(query_length)\n",
    "\n",
    "\n",
    "def calculate_documents_tf_idf_and_length():\n",
    "    length_for_doc = {}\n",
    "    for term in positional_index.keys():\n",
    "        for doc in positional_index[term][1].keys():\n",
    "            positions = positional_index[term][1][doc][0]\n",
    "            term_frequency = positional_index[term][1][doc][1]\n",
    "            inverted_doc_frequency = positional_index[term][0]\n",
    "            tf_idf = (1 + math.log2(term_frequency)) * (math.log2(len(content_dataset) / inverted_doc_frequency))\n",
    "            positional_index[term][1][doc] = (positions, term_frequency, tf_idf)\n",
    "            if doc in length_for_doc.keys():\n",
    "                length_for_doc[doc] += tf_idf ** 2\n",
    "            else:\n",
    "                length_for_doc[doc] = tf_idf ** 2\n",
    "\n",
    "    for doc in length_for_doc.keys():\n",
    "        length_for_doc[doc] = math.sqrt(length_for_doc[doc])\n",
    "    return length_for_doc\n",
    "\n",
    "\n",
    "def cosine_score(query, k, documents_length, champion_lists=None):\n",
    "    query_tf, query_length = calculate_query_tf_and_length(query)\n",
    "    doc_cosine_score_dic = {}\n",
    "    #     calculate cosine score\n",
    "    for term in query_tf.keys():\n",
    "        if champion_lists is not None:\n",
    "            if term in positional_index.keys():\n",
    "                for doc_id in champion_lists[term]:\n",
    "                    if doc_id in doc_cosine_score_dic.keys():\n",
    "                        doc_cosine_score_dic[doc_id] += query_tf[term] * positional_index[term][1][doc_id][2]\n",
    "                    else:\n",
    "                        doc_cosine_score_dic[doc_id] = query_tf[term] * positional_index[term][1][doc_id][2]\n",
    "        else:\n",
    "            if term in positional_index.keys():\n",
    "                for doc_id in positional_index[term][1].keys():\n",
    "                    if doc_id in doc_cosine_score_dic.keys():\n",
    "                        doc_cosine_score_dic[doc_id] += query_tf[term] * positional_index[term][1][doc_id][2]\n",
    "                    else:\n",
    "                        doc_cosine_score_dic[doc_id] = query_tf[term] * positional_index[term][1][doc_id][2]\n",
    "\n",
    "    for doc in doc_cosine_score_dic.keys():\n",
    "        doc_cosine_score_dic[doc] /= (documents_length[doc] * query_length)\n",
    "    #     Sort Documents by Score\n",
    "    sorted_doc_cosine_score = sorted(doc_cosine_score_dic.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_doc_cosine_score[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b87514",
   "metadata": {},
   "source": [
    "2.2 Calculate Jaccard Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e275e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_score(query, k, champion_lists=None):\n",
    "    query_set = set(query.split())\n",
    "    doc_jaccard_score_dic = {}\n",
    "    for term in query_set:\n",
    "        if term in positional_index.keys():\n",
    "            if champion_lists != None:\n",
    "                for doc_id in champion_lists[term]:\n",
    "                    if doc_id not in doc_jaccard_score_dic.keys():\n",
    "                        doc_set = set(hazm.word_tokenize(content_dataset[doc_id]))\n",
    "                        jaccard_score = len(query_set.intersection(doc_set)) / len(query_set.union(doc_set))\n",
    "                        doc_jaccard_score_dic[doc_id] = jaccard_score\n",
    "            else:\n",
    "                for doc_id in positional_index[term][1].keys():\n",
    "                    if doc_id not in doc_jaccard_score_dic.keys():\n",
    "                        doc_set = set(hazm.word_tokenize(content_dataset[doc_id]))\n",
    "                        jaccard_score = len(query_set.intersection(doc_set)) / len(query_set.union(doc_set))\n",
    "                        doc_jaccard_score_dic[doc_id] = jaccard_score\n",
    "    sorted_doc_jaccard_score = sorted(doc_jaccard_score_dic.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_doc_jaccard_score[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846308de",
   "metadata": {},
   "source": [
    "2.3 Create Champion Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57e22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_champion_lists(k, documents_length):\n",
    "    r = 4 * k\n",
    "    champion_lists = {}\n",
    "    for term in positional_index.keys():\n",
    "        doc_tf_idf = {}\n",
    "        for doc in positional_index[term][1].keys():\n",
    "            doc_tf_idf[doc] = positional_index[term][1][doc][2] / documents_length[doc]\n",
    "\n",
    "        sorted_doc_tf_idf = sorted(doc_tf_idf.items(), key=lambda item: item[1], reverse=True)\n",
    "        documents = []\n",
    "        for index, doc_score in enumerate(sorted_doc_tf_idf):\n",
    "            if index > r:\n",
    "                break\n",
    "            documents.append(doc_score[0])\n",
    "        champion_lists[term] = documents\n",
    "    return champion_lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c88c6",
   "metadata": {},
   "source": [
    "2.4 Show Ranked Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f4e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ranked_result(k_most_relavent_documents, query):\n",
    "    query_tf, _ = calculate_query_tf_and_length(query)\n",
    "    for doc_id, score in k_most_relavent_documents:\n",
    "        sentences = []\n",
    "        positions = []\n",
    "        print(\"Document \" + str(doc_id) + \": (Score: \" + \"{:.2f}\".format(score) + \")\")\n",
    "        print(title_dataset[doc_id])\n",
    "        doc_words = hazm.word_tokenize(content_dataset[doc_id])\n",
    "        for count, word in enumerate(doc_words):\n",
    "            if count in positions:\n",
    "                continue\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            if word in query_tf.keys():\n",
    "                sentence = ''\n",
    "                for k in range(count, -1, -1):\n",
    "                    positions.append(k)\n",
    "                    if doc_words[k] != '.':\n",
    "                        sentence = doc_words[k] + ' ' + sentence\n",
    "                    else:\n",
    "                        break\n",
    "                for j in range(count + 1, len(doc_words)):\n",
    "                    positions.append(j)\n",
    "                    if doc_words[j] != '.':\n",
    "                        sentence = sentence + ' ' + doc_words[j]\n",
    "                    else:\n",
    "                        sentence += '.'\n",
    "                        break\n",
    "\n",
    "                sentences.append(sentence)\n",
    "        for num, sentence in enumerate(sentences):\n",
    "            print(\"\\n        Sentence \" + str(num + 1) + \":\")\n",
    "            print(sentence + '\\n')\n",
    "\n",
    "\n",
    "def find_k_most_relavent_documents(query, k):\n",
    "    documents_length = calculate_documents_tf_idf_and_length()\n",
    "    champion_lists = create_champion_lists(k, documents_length)\n",
    "    cosine_score_documents = cosine_score(query, k, documents_length)\n",
    "    cosine_score_documents_champion_lists = cosine_score(query, k, documents_length, champion_lists)\n",
    "    jaccard_score_documents = jaccard_score(query, k)\n",
    "    jaccard_score_documents_champion_lists = jaccard_score(query, k, champion_lists)\n",
    "    print(\"Cosine Similarity: \\n\")\n",
    "    show_ranked_result(cosine_score_documents, query)\n",
    "    print(\"*******************************************\")\n",
    "    print(\"Cosine Similarity with Champion Lists: \\n\")\n",
    "    show_ranked_result(cosine_score_documents_champion_lists, query)\n",
    "    print(\"*******************************************\")\n",
    "    print(\"Jaccard Similarity: \\n\")\n",
    "    show_ranked_result(jaccard_score_documents, query)\n",
    "    print(\"*******************************************\")\n",
    "    print(\"Jaccard Similarity with Champion Lists: \\n\")\n",
    "    show_ranked_result(jaccard_score_documents_champion_lists, query)\n",
    "    print(\"*******************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce2132",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76791e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: \n",
      "\n",
      "Document 5073: (Score: 0.50)\n",
      "تیم ملی و ناظم الشریعه نامزد برترین های فوتسال جهان\n",
      "\n",
      "        Sentence 1:\n",
      "به ‌گزارش خبرنگار ورزش فارس ، سایت رسمی فوتسال  پلنت که هر ساله برترین‌های فوتسال جهان را معرفی می‌کند در سال ۲۰۲۱ هم برترین‌های فوتسال جهان را معرفی کرد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "نام سید محمد ناظم الشریعه سرمربی تیم‌ملی فوتسال  کشورمان و همچنین تیم ملی فوتسال ایران جزو ۱۰ گزینه نهایی انتخاب برترینهای فوتسال جهان قرار گرفته_است.\n",
      "\n",
      "Document 4502: (Score: 0.50)\n",
      "برگزاری مراسم معارفه سرمربی تیم ملی زیر 19 سال فوتسال+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، مراسم معارفه علی صانعی سرمربی تیم ملی زیر ۱۹ سال فوتسال  امروز با حضور احسان اصولی ، رییس کمیته فوتسال و حسین شمس برگزار شد.\n",
      "\n",
      "Document 4850: (Score: 0.47)\n",
      "شمسایی سرمربی تیم ملی فوتسال شد، صانعی مربی 19 ساله‌ها\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، نشست هیئت رئیسه فدراسیون فوتبال صبح امروز ( ۲۲ دی ماه ) در مرکز ملی فوتبال آغاز شد و در بخشی از مصوبات این جلسه ، ضمن تکریم محمد ناظم الشریعه بابت تلاش‌هایش برای فوتسال  ایران ، وحید شمسایی جهت هدایت تیم ملی فوتسال بزرگسالان انتخاب شد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "ضمن اینکه ، علی صانعی سرمربی تیم ملی فوتسال  زیر ۱۹ سال ایران شد.\n",
      "\n",
      "Document 990: (Score: 0.42)\n",
      "واکنش ناظم الشریعه به حضور در تیم ملی فوتسال عراق\n",
      "\n",
      "        Sentence 1:\n",
      "فوتسال  صحبت هایی کردیم.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "سرمربی سابق تیم ملی فوتسال  گفت : در این جلسه در مورد نحوه آموزش و پیشرفت فوتسال در عراق حرف هایی زدیم.\n",
      "\n",
      "\n",
      "        Sentence 3:\n",
      "با توجه به اینکه ایران به عنوان یک برند در فوتسال  دنیا شناخته_شده_است هر دو کشور می‌توانند در عرصه آموزش ، مربیگری و … حتی تغییر تفکر و.\n",
      "\n",
      "Document 5144: (Score: 0.41)\n",
      "3 ایرانی در جمع برترین های فوتسال جهان\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی فارس ، هرساله سایت معتبر فوتسال  پلنت برترین‌های فوتسال جهان را اعلام می‌کند ، از این رو نام سه نماینده ایران در جمع ۱۰ نفر برتر جهان دیده_می‌شود.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "گلاره ناظمی داور بین‌المللی فوتسال  کشورمان که برای اولین بار در تاریخ فوتسال ایران در تیم داوری فینال جام جهانی قرار گرفت ، در بین ۱۰ داور برتر قرار گرفته_است.\n",
      "\n",
      "\n",
      "        Sentence 3:\n",
      "فرزانه توسلی دروازه‌بان فصل گذشته سایپا و ملی‌پوش فوتسال  ایران در بین ۱۰ دروازه‌بان برتر بانوان جهان قرار دارد و در بخش برترین دروازه‌بانان هم ؛ نام علیرضا صمیمی سنگربان مس سونگون جزو ۱۰ دروازه‌بان برتر جهان قرار دارد.\n",
      "\n",
      "*******************************************\n",
      "Cosine Similarity with Champion Lists: \n",
      "\n",
      "Document 5073: (Score: 0.50)\n",
      "تیم ملی و ناظم الشریعه نامزد برترین های فوتسال جهان\n",
      "\n",
      "        Sentence 1:\n",
      "به ‌گزارش خبرنگار ورزش فارس ، سایت رسمی فوتسال  پلنت که هر ساله برترین‌های فوتسال جهان را معرفی می‌کند در سال ۲۰۲۱ هم برترین‌های فوتسال جهان را معرفی کرد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "نام سید محمد ناظم الشریعه سرمربی تیم‌ملی فوتسال  کشورمان و همچنین تیم ملی فوتسال ایران جزو ۱۰ گزینه نهایی انتخاب برترینهای فوتسال جهان قرار گرفته_است.\n",
      "\n",
      "Document 4502: (Score: 0.50)\n",
      "برگزاری مراسم معارفه سرمربی تیم ملی زیر 19 سال فوتسال+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، مراسم معارفه علی صانعی سرمربی تیم ملی زیر ۱۹ سال فوتسال  امروز با حضور احسان اصولی ، رییس کمیته فوتسال و حسین شمس برگزار شد.\n",
      "\n",
      "Document 4850: (Score: 0.47)\n",
      "شمسایی سرمربی تیم ملی فوتسال شد، صانعی مربی 19 ساله‌ها\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، نشست هیئت رئیسه فدراسیون فوتبال صبح امروز ( ۲۲ دی ماه ) در مرکز ملی فوتبال آغاز شد و در بخشی از مصوبات این جلسه ، ضمن تکریم محمد ناظم الشریعه بابت تلاش‌هایش برای فوتسال  ایران ، وحید شمسایی جهت هدایت تیم ملی فوتسال بزرگسالان انتخاب شد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "ضمن اینکه ، علی صانعی سرمربی تیم ملی فوتسال  زیر ۱۹ سال ایران شد.\n",
      "\n",
      "Document 990: (Score: 0.42)\n",
      "واکنش ناظم الشریعه به حضور در تیم ملی فوتسال عراق\n",
      "\n",
      "        Sentence 1:\n",
      "فوتسال  صحبت هایی کردیم.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "سرمربی سابق تیم ملی فوتسال  گفت : در این جلسه در مورد نحوه آموزش و پیشرفت فوتسال در عراق حرف هایی زدیم.\n",
      "\n",
      "\n",
      "        Sentence 3:\n",
      "با توجه به اینکه ایران به عنوان یک برند در فوتسال  دنیا شناخته_شده_است هر دو کشور می‌توانند در عرصه آموزش ، مربیگری و … حتی تغییر تفکر و.\n",
      "\n",
      "Document 5144: (Score: 0.41)\n",
      "3 ایرانی در جمع برترین های فوتسال جهان\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی فارس ، هرساله سایت معتبر فوتسال  پلنت برترین‌های فوتسال جهان را اعلام می‌کند ، از این رو نام سه نماینده ایران در جمع ۱۰ نفر برتر جهان دیده_می‌شود.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "گلاره ناظمی داور بین‌المللی فوتسال  کشورمان که برای اولین بار در تاریخ فوتسال ایران در تیم داوری فینال جام جهانی قرار گرفت ، در بین ۱۰ داور برتر قرار گرفته_است.\n",
      "\n",
      "\n",
      "        Sentence 3:\n",
      "فرزانه توسلی دروازه‌بان فصل گذشته سایپا و ملی‌پوش فوتسال  ایران در بین ۱۰ دروازه‌بان برتر بانوان جهان قرار دارد و در بخش برترین دروازه‌بانان هم ؛ نام علیرضا صمیمی سنگربان مس سونگون جزو ۱۰ دروازه‌بان برتر جهان قرار دارد.\n",
      "\n",
      "*******************************************\n",
      "Jaccard Similarity: \n",
      "\n",
      "Document 4502: (Score: 0.03)\n",
      "برگزاری مراسم معارفه سرمربی تیم ملی زیر 19 سال فوتسال+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، مراسم معارفه علی صانعی سرمربی تیم ملی زیر ۱۹ سال فوتسال  امروز با حضور احسان اصولی ، رییس کمیته فوتسال و حسین شمس برگزار شد.\n",
      "\n",
      "Document 258: (Score: 0.03)\n",
      "یک ایرانی سرمربی تیم ملی فوتسال اندونزی شد\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی خبرگزاری فارس ، محمد هاشم زاده مربی سابق تیم ملی و گیتی پسند به عنوان سرمربی جدید تیم ملی فوتسال  اندونزی معرفی شد.\n",
      "\n",
      "Document 137: (Score: 0.02)\n",
      "محرومیت 2 عضو فوتبال و فوتسال بانوان توسط کمیته اخلاق\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، باتوجه به قطعیت رای محکومیت عطیه محب‌زاده و الهام سلیمانی روزبهانی ، عطیه محب‌زاده به شش ماه محرومیت از کلیه فعالیت‌های مرتبط با فوتبال ، فوتسال  و فوتبال ساحلی و پرداخت پنجاه میلیون ریال جزای نقدی و الهام سلیمانی به یکسال محرومیت از کلیه فعالیت‌های مرتبط با فوتبال ، فوتسال و فوتبال ساحلی و پرداخت یکصد میلیون ریال جزای نقدی محکوم شد.\n",
      "\n",
      "Document 3686: (Score: 0.02)\n",
      "مسابقات کافا| پیروزی  5 گله تیم ملی فوتسال بانوان مقابل قرقیزستان\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس ، چهارمین دیدار تیم ملی فوتسال  بانوان ایران در تورنمنت کافا برابر قرقیزستان به پایان رسید که این دیدار با برتری ملی پوشان و با نتیجه۵ بر صفر به پایان رسید.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "گلهای تیم ملی فوتسال  بانوان را سحر پاپی ، فاطمه رحمتی ، نسترن مقیمی ، سارا شیربیگی و فرشته کریمی به ثمر رساندند.\n",
      "\n",
      "Document 4024: (Score: 0.02)\n",
      "بازیکن جوانان تیم ملی فوتسال به موراس پیوست+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس ، حامد خدایی بازیکن تیم ملی فوتسال  به تیم « موراس » قرقیزستان پیوست.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "خدایی در تیم فوتسال  جوانان ایران حضور داشته و در تیم‌های اهورای بهبهان و مقاومت البرز هم به بازی کرده_است.\n",
      "\n",
      "*******************************************\n",
      "Jaccard Similarity with Champion Lists: \n",
      "\n",
      "Document 4502: (Score: 0.03)\n",
      "برگزاری مراسم معارفه سرمربی تیم ملی زیر 19 سال فوتسال+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، مراسم معارفه علی صانعی سرمربی تیم ملی زیر ۱۹ سال فوتسال  امروز با حضور احسان اصولی ، رییس کمیته فوتسال و حسین شمس برگزار شد.\n",
      "\n",
      "Document 5073: (Score: 0.02)\n",
      "تیم ملی و ناظم الشریعه نامزد برترین های فوتسال جهان\n",
      "\n",
      "        Sentence 1:\n",
      "به ‌گزارش خبرنگار ورزش فارس ، سایت رسمی فوتسال  پلنت که هر ساله برترین‌های فوتسال جهان را معرفی می‌کند در سال ۲۰۲۱ هم برترین‌های فوتسال جهان را معرفی کرد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "نام سید محمد ناظم الشریعه سرمربی تیم‌ملی فوتسال  کشورمان و همچنین تیم ملی فوتسال ایران جزو ۱۰ گزینه نهایی انتخاب برترینهای فوتسال جهان قرار گرفته_است.\n",
      "\n",
      "Document 4872: (Score: 0.02)\n",
      "افتتاح خانه فوتسال با درخواست جالب عزیزی‌خادم از عضو هیات رئیسه فدراسیون\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس ، پیش از جلسه امروز هیات رئیسه فدراسیون فوتبال اعضای این هیات رئیسه اقدام به افتتاح خانه فوتسال  مرکز ملی فوتبال کردند.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "قرار است تمام فعالیت‌های رشته فوتسال  از این به بعد در این مرکز انجام شود.\n",
      "\n",
      "Document 5321: (Score: 0.02)\n",
      "مقدماتی جام ملت‌های فوتسال آسیا| ایران همگروه میزبان شد+عکس\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرگزاری فارس ، سایت کنفدراسیون فوتبال آسیا قرعه کشی مرحله گروهی مقدماتی جام ملت‌های آسیا فوتسال  ۲۰۲۲ را اعلام کرد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "در این قرعه کشی تیم ملی فوتسال  کشورمان در گروه اول قرقیزستان ، ترکمنستان و مالدیو رقیب شد.\n",
      "\n",
      "\n",
      "        Sentence 3:\n",
      "مسابقات مقدماتی جام ملت‌های فوتسال  آسیا ۲۰۲۲ به میزبانی قرقیزستان از تاریخ ۱۲ الی ۲۷ فروردین برگزار می‌شود.\n",
      "\n",
      "Document 4850: (Score: 0.02)\n",
      "شمسایی سرمربی تیم ملی فوتسال شد، صانعی مربی 19 ساله‌ها\n",
      "\n",
      "        Sentence 1:\n",
      "به گزارش خبرنگار ورزشی خبرگزاری فارس و به نقل از سایت فدراسیون فوتبال ، نشست هیئت رئیسه فدراسیون فوتبال صبح امروز ( ۲۲ دی ماه ) در مرکز ملی فوتبال آغاز شد و در بخشی از مصوبات این جلسه ، ضمن تکریم محمد ناظم الشریعه بابت تلاش‌هایش برای فوتسال  ایران ، وحید شمسایی جهت هدایت تیم ملی فوتسال بزرگسالان انتخاب شد.\n",
      "\n",
      "\n",
      "        Sentence 2:\n",
      "ضمن اینکه ، علی صانعی سرمربی تیم ملی فوتسال  زیر ۱۹ سال ایران شد.\n",
      "\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "query = \"فوتسال\"\n",
    "k = 5\n",
    "find_k_most_relavent_documents(query, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
